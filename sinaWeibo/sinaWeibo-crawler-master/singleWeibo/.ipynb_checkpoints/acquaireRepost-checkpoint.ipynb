{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@[TOC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import xlwt\n",
    "import  re\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#根据个人浏览器信息进行修改\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'\n",
    "    ,\n",
    "    'Cookie': 'XSRF-TOKEN=iHSSfLhkn7eDp8GVlnPRjVcZ; _s_tentry=weibo.com; Apache=7501175482651.093.1661152778304; SINAGLOBAL=7501175482651.093.1661152778304; ULV=1661152779117:1:1:1:7501175482651.093.1661152778304:; login_sid_t=c285447e6dbe81a23103af81a13af630; cross_origin_proto=SSL; wb_view_log=1920*10801; ALF=1692689021; SSOLoginState=1661153021; SUB=_2A25OB16uDeRhGeNJ6lUT9SfMyjSIHXVtdTdmrDV8PUNbmtANLXShkW9NS-TN0XoV2zrBzz8-AU1Bm_9loUL1RXvr; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9W5D8615S5j4Ho8woelwSafF5JpX5KzhUgL.Fo-NeKMESK.7eKn2dJLoI0YLxKBLBonL1h5LxK-L1-zLBKzLxKMLBoeL1-qLxKML1-2L1hBLxK-LBo5L12qLxK.LB.zL1K2LxK-LB-BL1K5t; WBPSESS=aaw_JdgPytptDtbswt-VmPS3sKBUSOFh1KiWznHS7BvuUEP35S_j7K0a3fodOejoHnU-Dnvy0R37HX3ecz2FM6BOsNaSMGBGiCh0HO7_b5ak5taq-YTsTG0FxS3wmYjlZlorQA8zD39EaLrgWZO_Kg=='\n",
    "    #'ALF=1581501545; _T_WM=67706607048; H5_wentry=H5; backURL=https%3A%2F%2Fm.weibo.cn%2Fapi%2Fcomments%2Fshow%3Fid%3DIr5j4iRXW%26page%3D3; XSRF-TOKEN=11216a; WEIBOCN_FROM=1110006030; MLOGIN=1; SSOLoginState=1580006602; SCF=AqQddu0eGCw6Wh1xPsTyigWBFJH-P0ACsyLUFzNakys5zFt06rZeA1gEI0iP7HfWxZntbpMr8WTWhrxEdSVGB58.; SUB=_2A25zKIyaDeRhGeNP41UT9yjIyj6IHXVQ0hTSrDV6PUJbktAKLRL-kW1NTk4PgHLYgtoeuxFzuGDIDcybzoEoXvq9; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9W5q.Hx0pIs7PKpACzdnFYSZ5JpX5KzhUgL.Fo-p1hMES0qXeKz2dJLoIpUeBc8EdFH8SC-4BbHFSFH81F-RSF-4Sntt; SUHB=0IIlrfWMMkVsTI; M_WEIBOCN_PARAMS=uicode%3D20000174'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件保存地址\n",
    "addrRoot='./dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#是否获取转发者具体个人信息\n",
    "getConcreteInfoList=False#True#\n",
    "isLogin=False#True\n",
    "\n",
    "#是否登入采集个人信息\n",
    "\n",
    "#无信息打印字符\n",
    "infoNoExistStr='未知'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#是否处理微博文本内容\n",
    "processText = False#True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造表格，采集数据内容（修改这里获取想要的信息）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "博主的信息单独收集：转发的：转发reposts_count、评论comments_count、点赞数量attitudes_count、粉丝数量followers_count\n",
    "\n",
    "    原始的retweeted_status：转发reposts_count、评论comments_count、点赞数量attitudes_count\n",
    "                            原始用户的user：用户名screen_name、id、粉丝数量followers_count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "获取个人具体信息范围、排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#获取个人具体信息范围、排列\n",
    "infoRangeDict={\n",
    "'性别':True,\n",
    "'所在地':True,\n",
    "    \n",
    "'生日':False,\n",
    "'家乡':False,\n",
    "'公司':True,\n",
    "'大学':True,\n",
    "    \n",
    "'昵称':False,\n",
    "'简介':False,\n",
    "'注册时间':False,\n",
    "'阳光信用':False,\n",
    "    \n",
    "    #若无信息显示\n",
    "'infoNoExist':'未知'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "获取博文信息范围、排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#获取博文信息范围、排列\n",
    "blogRangeDict={\n",
    "'visible': False,#{type: 0, list_id: 0}\n",
    "    \n",
    "'created_at': True,#\"20分钟前\"\n",
    "    \n",
    "'id': False,#\"4466073829119710\"\n",
    "'idstr': False,#\"4466073829119710\"\n",
    "'mid': False,#\"4466073829119710\"\n",
    "'can_edit': False,#false\n",
    "'show_additional_indication': False,#0\n",
    "    \n",
    "'text': True,#\"【情况通报】2019年12月31日，武汉市卫健部门发布关于肺炎疫情的情况通报。\n",
    "    \n",
    "'textLength': False,#452\n",
    "'source': False,#\"360安全浏览器\"\n",
    "'favorited': False,#false\n",
    "'pic_types': False,#\"\"\n",
    "'is_paid': False,#false\n",
    "'mblog_vip_type': False,#0\n",
    "'user': False,#{id: 2418542712, screen_name: \"平安武汉\",…}\n",
    "    \n",
    "'reposts_count': True,#1035\n",
    "'comments_count': True,#1886\n",
    "'attitudes_count': True,#7508\n",
    "    \n",
    "'pending_approval_count': False,#0\n",
    "'isLongText': False,#true\n",
    "'reward_exhibition_type':False,# 0\n",
    "'hide_flag': False,#0\n",
    "'mblogtype': False,#0\n",
    "'more_info_type': False,#0\n",
    "'cardid': False,#\"star_11247_common\"\n",
    "'content_auth': False,#0\n",
    "'pic_num': False,#0\n",
    "    \n",
    "#若无相关信息，则显示：\n",
    "'infoNoExist':'未知'\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "获取博主信息范围、排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#获取博主信息范围、排列\n",
    "userRangeDict={\n",
    "'id':True,# 1323527941\n",
    "'screen_name': True,#\"Vista看天下\"\n",
    "    \n",
    "'profile_image_url': False,#\"https://tva2.sinaimg.cn/crop.0.0.180.180.180/4ee36f05jw1e8qgp5bmzyj2050050aa8.jpg?KID=imgbed,tva&Expires=1580290462&ssig=xPIoKDRR56\"\n",
    "'profile_url':False,# \"https://m.weibo.cn/u/1323527941?uid=1323527941&luicode=10000011&lfid=1076031323527941\"\n",
    "'statuses_count': False,#微博数 77256\n",
    "'verified': False,#true\n",
    "'verified_type':False,# 3\n",
    "'verified_type_ext': False,#0\n",
    "'verified_reason': False,#\"《Vista看天下》官方微博\"\n",
    "'close_blue_v': False,#false\n",
    "    \n",
    "'description': True,#\"一个有趣的蓝V\"\n",
    "'gender': True,# \"m\"\n",
    "    \n",
    "'mbtype': False,#12\n",
    "'urank': False,#48\n",
    "'mbrank': False,#6\n",
    "'follow_me':False,# false\n",
    "'following':False,# false\n",
    "    \n",
    "'followers_count': True,#19657897\n",
    "'follow_count': True,#1809\n",
    "    \n",
    "'cover_image_phone': False,#\"https://tva1.sinaimg.cn/crop.0.0.640.640.640/549d0121tw1egm1kjly3jj20hs0hsq4f.jpg\"\n",
    "'avatar_hd': False,#\"https://ww2.sinaimg.cn/orj480/4ee36f05jw1e8qgp5bmzyj2050050aa8.jpg\"\n",
    "'like': False,#false\n",
    "'like_me': False,#false\n",
    "'badge': False,#{enterprise: 1, gongyi_level: 1, bind_taobao: 1, dzwbqlx_2016: 1, follow_whitelist_video: 1,…}\n",
    "    \n",
    "#若无信息显示\n",
    "'infoNoExist':'未知'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件命名"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "使用示例:\n",
    "tweeter='王'\n",
    "fp = open(addrFile(tweeter),'w+',newline='',encoding='utf-16')\n",
    "fp.close()\n",
    "\n",
    "使用库函数：\n",
    "os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addrFile(tweeter,suffix):\n",
    "    path=addrRoot+str(tweeter)+'/'\n",
    "    if os.path.exists(path) is False:\n",
    "         os.makedirs(path)\n",
    "    address=path+tweeter+suffix+'.csv'\n",
    "    return address  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成信息标题"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "将字典Dict中为True的条目生成标题,加前缀prefix\n",
    "\n",
    "使用实例：\n",
    "print(getInfoTitle(blogRangeDict,'原文'))\n",
    "打印结果：\n",
    "['原文created_at', '原文text', '原文reposts_count', '原文comments_count', '原文attitudes_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getInfoTitle(Dict,prefix):\n",
    "    titleList=[]\n",
    "    for item in Dict:\n",
    "        if(Dict.get(item) is True):\n",
    "            titleList.append(prefix+item)\n",
    "    return (titleList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工具类，用来去除爬取的正文中一些不需要的链接、标签等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#工具类，用来去除爬取的正文中一些不需要的链接、标签等\n",
    "class Tool:\n",
    "    deleteImg = re.compile('<img.*?>')\n",
    "    newLine =re.compile('<tr>|<div>|</tr>|</div>')\n",
    "    deleteAite = re.compile('//.*?:')\n",
    "    deleteAddr = re.compile('<a.*?>.*?</a>|<a href='+'\\'https:')\n",
    "    deleteTag = re.compile('<.*?>')\n",
    "    deleteWord = re.compile('回复@|回覆@|回覆|回复')\n",
    " \n",
    "    @classmethod\n",
    "    def replace(cls,x):\n",
    "        x = re.sub(cls.deleteWord,'',x)\n",
    "        x = re.sub(cls.deleteImg,'',x)\n",
    "        x = re.sub(cls.deleteAite,'',x)\n",
    "        x = re.sub(cls.deleteAddr, '', x)\n",
    "        x = re.sub(cls.newLine,'',x)\n",
    "        x = re.sub(cls.deleteTag,'',x)\n",
    "        return x.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造微博转发信息的url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def repostURL(id,pages):\n",
    "    urls=[]\n",
    "    for page in pages:\n",
    "        if page != 0:\n",
    "            urls+=['https://m.weibo.cn/api/statuses/repostTimeline?id='+str(id)+'&page='+str(page)]\n",
    "    print(urls)\n",
    "    return urls   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#将字典类型的信息格式传递为需要的信息列表\n",
    "def getInfoList(infoDict,rangeDict):\n",
    "    infoList=[]\n",
    "    for item in rangeDict:\n",
    "        if rangeDict.get(item) is True:\n",
    "            content=infoDict.get(item)\n",
    "            if content is not None:\n",
    "                #处理微博文本内容  \n",
    "                if item =='text':\n",
    "                    if processText is True:\n",
    "                        content=Tool.replace(content)\n",
    "                infoList.append(content)      \n",
    "            else:\n",
    "                infoList.append(rangeDict['infoNoExist'])\n",
    "    return infoList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬取所有转发信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###在已有的一系列urls中进行操作\n",
    "###筛选出微博转发内容进行操作\n",
    "def reRatio(urls,csvWriter):\n",
    "    \n",
    "    notEnd= True\n",
    "    \n",
    "    retweetBlogTitle=getInfoTitle(blogRangeDict,'转发')#转发博文信息标题\n",
    "    retweetUserTitle=getInfoTitle(userRangeDict,'转发')#转发博主信息标题\n",
    "    \n",
    "    \n",
    "    infoTitle=getInfoTitle(infoRangeDict,'')#原文博主个人主页信息标题\n",
    "    \n",
    "    #写表格的标题\n",
    "    if getConcreteInfoList is True:       \n",
    "        csvWriter.writerow(retweetBlogTitle+retweetUserTitle+infoTitle)        \n",
    "    else:\n",
    "        csvWriter.writerow(retweetBlogTitle+retweetUserTitle)\n",
    "        \n",
    "    for url in urls:        \n",
    "        \n",
    "        response = requests.get(url,headers=headers)\n",
    "        txt=response.text\n",
    "        print(drillInfo(txt))\n",
    "        resjson = json.loads(response.text)    \n",
    "        state=resjson['ok']\n",
    "        #结束最后\n",
    "        if(state==0):\n",
    "            notEnd=False\n",
    "            break\n",
    "        \n",
    "        cards=resjson['data']['data']      \n",
    "        \n",
    "        #print(cards)\n",
    "        \n",
    "        #结束最后\n",
    "        if(len(cards)==1):\n",
    "            notEnd=False\n",
    "            break\n",
    "        #遍历一个页面的所有微博    \n",
    "        for card in cards:\n",
    "            try:\n",
    "                #转发博文与博主信息\n",
    "                retweetBlogInfoDict=card \n",
    "                retweetUserInfoDict=retweetBlogInfoDict['user']      \n",
    "                \n",
    "                #构造填入csv文件数据列表\n",
    "                infoList=[]                            \n",
    "\n",
    "                #转发博文数据\n",
    "                retweetBlogInfoList=getInfoList(retweetBlogInfoDict,blogRangeDict)               \n",
    "                infoList+=retweetBlogInfoList   \n",
    "                \n",
    "                #转发博主数据\n",
    "                ##默认已知\n",
    "                retweetUserInfoList=getInfoList(retweetUserInfoDict,userRangeDict)               \n",
    "                infoList+=retweetUserInfoList  \n",
    "                \n",
    "                                  \n",
    "\n",
    "                if getConcreteInfoList is True:\n",
    "                    infoDict=getInfo(isLogin,originUserID)\n",
    "                    otherInfoList=getInfoList(infoDict,infoRangeDict)      \n",
    "                    infoList+=otherInfoList                          \n",
    "                #print(infoList)               \n",
    "                #保存数据至csv\n",
    "                csvWriter.writerow(infoList)                       \n",
    "\n",
    "                #不断获取该博主对的影响力\n",
    "                #break\n",
    "            except:\n",
    "                pass            \n",
    "        #延时，防止反爬\n",
    "        time.sleep(3)\n",
    "        \n",
    "    return notEnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取个人主页中信息"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "使用示例：\n",
    "response = requests.get(url)\n",
    "txt=response.text\n",
    "print(drillInfo(txt))\n",
    "\n",
    "结果如下：\n",
    "{'昵称': '甘肃华熙文化',\n",
    " '简介': '【马丛珊.禅绣艺术，世界纹绣大师学院甘肃分院】服务生命之美；践行匠心为本，艺心创造，慈心发扬校训，微信mashan5374，☎13109439909',\n",
    " '性别': '女',\n",
    " '所在地': '甘肃 兰州'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drillInfo(txt):\n",
    "    keyInfo={}\n",
    "    \n",
    "    try:  \n",
    "        resjson = json.loads(txt)  \n",
    "        infodata = resjson.get('data')\n",
    "        cards = infodata.get('cards')\n",
    "        for l in range(0,len(cards)):\n",
    "            temp = cards[l]\n",
    "            card_group = temp.get('card_group')            \n",
    "            #判断获取信息类型                     \n",
    "            for card in card_group:                \n",
    "                #将信息传入字典\n",
    "                name=card.get('item_name')\n",
    "                if name is not None:\n",
    "                    content=card.get('item_content')\n",
    "                    keyInfo[name]=content \n",
    "    except:\n",
    "        pass\n",
    "    return keyInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  构建通过id访问个人主页的url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infoUrl(id):\n",
    "    url = \"https://m.weibo.cn/api/container/getIndex?containerid=230283\"+str(id)+\"_-_INFO\" \n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取某id博主的个人信息"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "为防止反复爬取，将原文整体保存为文件，格式为 信息卡片长度（2 or 5）+id+博主id\n",
    "不登录2含有性别、所在地\n",
    "登录5含有性别、所在地、星座、大学、公司等完整信息\n",
    "若存在所需文件，则从文件读取信息，否则爬取，同时保存文件\n",
    "\n",
    "若爬取未成功，返回-1\n",
    "\n",
    "使用库函数：\n",
    "os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getInfo(state,id):\n",
    "    \n",
    "    address=addrRoot+'info/'+str(state)+'id'+str(id)+'.txt'\n",
    "    path=addrRoot+'info/'\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)\n",
    "    try:\n",
    "        #已有文件\n",
    "        if(os.path.exists(address)==True):\n",
    "            fp = open(address,'r',encoding='utf-16')\n",
    "            txt=fp.read()\n",
    "            info=drillInfo(txt)\n",
    "            fp.close()\n",
    "        else:  \n",
    "            fp = open(address,'w+',encoding='utf-16')\n",
    "            url=infoUrl(id)\n",
    "            if state is True:\n",
    "                response = requests.get(url,headers=headers)\n",
    "            else:\n",
    "                response = requests.get(url)\n",
    "            txt=response.text\n",
    "            fp.write(response.text)        \n",
    "            info=drillInfo(txt)\n",
    "            fp.close()\n",
    "    except:\n",
    "        info=-1     \n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "获取特定个人信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getExatInfo(item,state,id):\n",
    "    info=getInfo(state,id)\n",
    "    content=info.get(item)\n",
    "    if content is not None:\n",
    "        return content\n",
    "    else:\n",
    "        return infoNoExistStr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  构造热门界面访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadData(id):\n",
    "    #tweeter=getExatInfo('昵称',2,int(id))\n",
    "    tweeter='kobe'\n",
    "    batch=0\n",
    "    \n",
    "    \n",
    "    while(1):\n",
    "        ranges=range(20*batch,20*(batch+1))\n",
    "\n",
    "        fileAddr=addrFile(tweeter,'batch'+str(batch))\n",
    "        if os.path.exists(fileAddr) is True:\n",
    "            print(fileAddr+'已存在，跳过采集')                \n",
    "        else:\n",
    "            print('文件将写入：'+fileAddr)\n",
    "            fp = open(fileAddr,'w+',newline='',encoding='utf-16')\n",
    "            writer=csv.writer(fp)\n",
    "            if reRatio(repostURL(id,ranges),writer) is False:\n",
    "                fp.close()\n",
    "                break\n",
    "\n",
    "            fp.close()\n",
    "            print('第'+str(batch)+'批数据已记录完毕')\n",
    "        batch+=1        \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#陈赫\n",
    "id=1574684061\n",
    "#MorningGlory_肖战资源博\n",
    "id=5735501478\n",
    "\n",
    "#靳东\n",
    "id=1093897112\n",
    "#李健\n",
    "id=1744395855\n",
    "\n",
    "#干部\n",
    "id=6472269230\n",
    "\n",
    "#陶勇\n",
    "id=5899876484\n",
    "\n",
    "#姚晨\n",
    "id=1266321801\n",
    "\n",
    "#鞠婧祎\n",
    "id=3669102477\n",
    "\n",
    "#韩红\n",
    "#id=1922542315\n",
    "\n",
    "\n",
    "#穿帮君\n",
    "id=5671786192\n",
    "\n",
    "#汉堡爸爸\n",
    "id=2784421224\n",
    "\n",
    "#蔡徐坤\n",
    "\n",
    "id=1776448504\n",
    "\n",
    "\n",
    "#林书豪\n",
    "id=2106855375\n",
    "\n",
    "#干部\n",
    "id=6472269230\n",
    "\n",
    "#任嘉伦\n",
    "id=3800468188\n",
    "\n",
    "#肖战\n",
    "id=1792951112\n",
    "\n",
    "\n",
    "#迪丽热巴\n",
    "id=1669879400\n",
    "\n",
    "\n",
    "#科比\n",
    "id=3264072325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "博文id： 3264072325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/kebi视频-郭杰瑞/视频-郭杰瑞batch0.csv已存在，跳过采集\n",
      "./dataset/kebi视频-郭杰瑞/视频-郭杰瑞batch1.csv已存在，跳过采集\n",
      "文件将写入：./dataset/kebi视频-郭杰瑞/视频-郭杰瑞batch2.csv\n",
      "{}\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m博文id：\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#4102228300324979\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#4466810701697847武汉肺炎\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#4465738137650546\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdownloadData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mdownloadData\u001b[1;34m(id)\u001b[0m\n\u001b[0;32m     15\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(fileAddr,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m'\u001b[39m,newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m writer\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mwriter(fp)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mreRatio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepostURL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     fp\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mreRatio\u001b[1;34m(urls, csvWriter)\u001b[0m\n\u001b[0;32m     22\u001b[0m txt\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(drillInfo(txt))\n\u001b[1;32m---> 24\u001b[0m resjson \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     25\u001b[0m state\u001b[38;5;241m=\u001b[39mresjson[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#结束最后\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "id=input('博文id：')\n",
    "#4102228300324979\n",
    "#4466810701697847武汉肺炎\n",
    "#4465738137650546\n",
    "downloadData(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
